# References

- Hastie, et. al. 2009. [The Elements of Statistical Learning, 2ed](https://web.stanford.edu/~hastie/ElemStatLearn/printings/ESLII_print12.pdf)

> *Chapter 14: In this chapter we address unsupervised learning, or "learning without a teacher"...we present those unsupervised learning
techniques that are among the most commonly used in practice, and additionally, a few others that are favored by the authors.*

- Cohen-Addad, et. al. 2017. [Hierarchical Clustering: Objective Functions and Algorithms](https://arxiv.org/pdf/1704.02147.pdf)

>*We take an axiomatic approach to defining ‘good’ objective functions for both similarity and dissimilarity-based hierarchical clustering. We characterize a set of admissible objective functions ... that have the property that when the input admits a ‘natural’ ground-truth hierarchical clustering, the 
ground-truth clustering has an optimal value.*


- Aloise, et. al. 2009. [NP-hardness of Euclidean sum-of-squares clustering](https://link.springer.com/article/10.1007/s10994-009-5103-0)

>*A recent proof of NP-hardness of Euclidean sum-of-squares clustering, due to Drineas et al. (Mach. Learn. 56:9–33, 2004), is not valid. An alternate short proof is provided.*

- Mahajan, et. al. 2012. [The planar k-means problem is NP-hard](https://core.ac.uk/download/pdf/82786926.pdf)

>*...the k-means problem is NP-hard when the dimension m is part of the input even for k = 2. However, to the best of our knowledge, there is no known NP-hardness result when the dimension m is fixed and k, the number of clusters, is part of the input...
In this paper, we establish the NP-hardness of the k-means problem in the plane.*


- Linderman, Steinerberger. 2017. [Clustering with t-SNE, provably](https://arxiv.org/abs/1706.02582)

>*t-distributed Stochastic Neighborhood Embedding (t-SNE), a clustering and visualization method proposed by van der Maaten & Hinton in 2008, has rapidly become a standard tool in a number of natural sciences. Despite its overwhelming success, there is a distinct lack of mathematical foundations and the inner workings of the algorithm are not well understood. The purpose of this paper is to prove that t-SNE is able to recover well-separated clusters; more precisely, we prove that t-SNE in the `early exaggeration' phase, an optimization technique proposed by van der Maaten & Hinton (2008) and van der Maaten (2014), can be rigorously analyzed.*

- Arora, et. al. 2018. [An analysis of the t-SNE algorithm for Data Visualization](https://arxiv.org/abs/1803.01768)

>*This work gives a formal framework for the problem of data visualization - finding a 2-dimensional embedding of clusterable data that correctly separates individual clusters to make them visually identifiable. We then give a rigorous analysis of the performance of t-SNE under a natural, deterministic condition on the "ground-truth" clusters (similar to conditions assumed in earlier analyses of clustering) in the underlying data.*

- McNicholas, 2016. [Model-Based Clustering](https://link.springer.com/article/10.1007/s00357-016-9211-9)

>*The notion of defining a cluster as a component in a mixture model was put forth by Tiedeman in 1955; since then, the use of mixture models for clustering has grown into an important subfield of classification. Considering the volume of work within this field over the past decade, which seems equal to all of that which went before, a review of work to date is timely. First, the definition of a cluster is discussed and some historical context for model-based clustering is provided. Then, starting with Gaussian mixtures, the evolution of model-based clustering is traced, from the famous paper by Wolfe in 1965 to work that is currently available only in preprint form. This review ends with a look ahead to the next decade or so.*

- McLachlan and Basford. 1988.  Mixture Models: inference and applications to clustering. (Book)

- McLachlan, et. al. 2018.  [Finite Mixture Models](https://www.annualreviews.org/doi/full/10.1146/annurev-statistics-031017-100325).

>*The aim of this article is to provide an up-to-date account of the theory and methodological developments underlying the applications of finite mixture models. Because of their flexibility, mixture models are being increasingly exploited as a convenient, semiparametric way in which to model unknown distributional shapes. This is in addition to their obvious applications where there is group-structure in the data or where the aim is to explore the data for such structure, as in a cluster analysis.*
